{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26a1b7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 所有依赖加载成功\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # 无GUI后端\n",
    "\n",
    "from datasets import load_from_disk\n",
    "import cv2\n",
    "import librosa\n",
    "import librosa.display\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ 所有依赖加载成功\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17264b4f",
   "metadata": {},
   "source": [
    "## 1. 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f38d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 数据集加载成功\n",
      "总样本数: 1660\n",
      "\n",
      "字段列表: ['id', 'speaker_video_path', 'speaker_audio_path', 'listener_video_path', 'listener_audio_path', 'listener_au_names', 'listener_au_prob', 'listener_au_act', 'listener_frame_idx', 'fps', 'duration', 'n_frames']\n"
     ]
    }
   ],
   "source": [
    "# 加载训练集\n",
    "dataset_path = \"/mnt/iusers01/fatpou01/compsci01/k09562zs/scratch/LLM_reaction_Robot/Reaction_DataSet/processed/train\"\n",
    "train_ds = load_from_disk(dataset_path)\n",
    "\n",
    "print(f\"✅ 数据集加载成功\")\n",
    "print(f\"总样本数: {len(train_ds)}\")\n",
    "print(f\"\\n字段列表: {train_ds.column_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb16ea6",
   "metadata": {},
   "source": [
    "## 2. 选择一个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfbb93c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本ID: Camera-2024-06-21-103121-103102\n",
      "\n",
      "视频信息:\n",
      "  - FPS: 30.0\n",
      "  - 时长: 27.07秒\n",
      "  - 总帧数: 812\n",
      "\n",
      "Speaker (输入):\n",
      "  - Video: Camera-2024-06-21-103121-103102.mp4\n",
      "  - Audio: Camera-2024-06-21-103121-103102.wav\n",
      "\n",
      "Listener (目标):\n",
      "  - Video: Camera-2024-06-21-103121-103102.mp4\n",
      "  - Audio: Camera-2024-06-21-103121-103102.wav\n",
      "\n",
      "AU标签:\n",
      "  - AU数量: 17\n",
      "  - AU列表: ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU18', 'AU20', 'AU23', 'AU25', 'AU26']\n"
     ]
    }
   ],
   "source": [
    "# 选择第0个样本\n",
    "sample_idx = 0\n",
    "sample = train_ds[sample_idx]\n",
    "\n",
    "print(f\"样本ID: {sample['id']}\")\n",
    "print(f\"\\n视频信息:\")\n",
    "print(f\"  - FPS: {sample['fps']}\")\n",
    "print(f\"  - 时长: {sample['duration']:.2f}秒\")\n",
    "print(f\"  - 总帧数: {sample['n_frames']}\")\n",
    "print(f\"\\nSpeaker (输入):\")\n",
    "print(f\"  - Video: {Path(sample['speaker_video_path']).name}\")\n",
    "print(f\"  - Audio: {Path(sample['speaker_audio_path']).name}\")\n",
    "print(f\"\\nListener (目标):\")\n",
    "print(f\"  - Video: {Path(sample['listener_video_path']).name}\")\n",
    "print(f\"  - Audio: {Path(sample['listener_audio_path']).name}\")\n",
    "print(f\"\\nAU标签:\")\n",
    "print(f\"  - AU数量: {len(sample['listener_au_names'])}\")\n",
    "print(f\"  - AU列表: {sample['listener_au_names']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc00c427",
   "metadata": {},
   "source": [
    "## 3. 加载视频帧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3880ea66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载 Speaker 视频帧...\n",
      "✅ 已加载 6 帧\n",
      "\n",
      "加载 Listener 视频帧...\n",
      "✅ 已加载 6 帧\n"
     ]
    }
   ],
   "source": [
    "def load_video_frames(video_path, max_frames=6):\n",
    "    \"\"\"均匀采样视频帧\"\"\"\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # 均匀采样\n",
    "    frame_indices = np.linspace(0, total_frames-1, max_frames, dtype=int)\n",
    "    frames = []\n",
    "    \n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame_rgb)\n",
    "    \n",
    "    cap.release()\n",
    "    return frames, frame_indices\n",
    "\n",
    "# 加载Speaker和Listener视频帧\n",
    "print(\"加载 Speaker 视频帧...\")\n",
    "speaker_frames, speaker_indices = load_video_frames(sample['speaker_video_path'], max_frames=6)\n",
    "print(f\"✅ 已加载 {len(speaker_frames)} 帧\")\n",
    "\n",
    "print(\"\\n加载 Listener 视频帧...\")\n",
    "listener_frames, listener_indices = load_video_frames(sample['listener_video_path'], max_frames=6)\n",
    "print(f\"✅ 已加载 {len(listener_frames)} 帧\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b4d56",
   "metadata": {},
   "source": [
    "## 4. 加载音频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa848416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载 Speaker 音频...\n",
      "✅ 采样率: 16000 Hz, 时长: 27.05秒\n",
      "\n",
      "加载 Listener 音频...\n",
      "✅ 采样率: 16000 Hz, 时长: 27.05秒\n"
     ]
    }
   ],
   "source": [
    "# 加载音频\n",
    "print(\"加载 Speaker 音频...\")\n",
    "speaker_audio, sr_speaker = librosa.load(sample['speaker_audio_path'], sr=None)\n",
    "print(f\"✅ 采样率: {sr_speaker} Hz, 时长: {len(speaker_audio)/sr_speaker:.2f}秒\")\n",
    "\n",
    "print(\"\\n加载 Listener 音频...\")\n",
    "listener_audio, sr_listener = librosa.load(sample['listener_audio_path'], sr=None)\n",
    "print(f\"✅ 采样率: {sr_listener} Hz, 时长: {len(listener_audio)/sr_listener:.2f}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f33334",
   "metadata": {},
   "source": [
    "## 5. 可视化：视频帧对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185299b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'scratch/LLM_reaction_Robot/visualization_frames.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m plt.tight_layout()\n\u001b[32m     18\u001b[39m output_path = \u001b[33m'\u001b[39m\u001b[33mscratch/LLM_reaction_Robot/visualization_frames.png\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m plt.savefig(output_path, dpi=\u001b[32m150\u001b[39m, bbox_inches=\u001b[33m'\u001b[39m\u001b[33mtight\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ 视频帧对比图已保存: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m plt.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/React311/lib/python3.11/site-packages/matplotlib/pyplot.py:1243\u001b[39m, in \u001b[36msavefig\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1240\u001b[39m fig = gcf()\n\u001b[32m   1241\u001b[39m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[32m   1242\u001b[39m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m res = fig.savefig(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[32m   1244\u001b[39m fig.canvas.draw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/React311/lib/python3.11/site-packages/matplotlib/figure.py:3490\u001b[39m, in \u001b[36mFigure.savefig\u001b[39m\u001b[34m(self, fname, transparent, **kwargs)\u001b[39m\n\u001b[32m   3488\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axes:\n\u001b[32m   3489\u001b[39m         _recursively_make_axes_transparent(stack, ax)\n\u001b[32m-> \u001b[39m\u001b[32m3490\u001b[39m \u001b[38;5;28mself\u001b[39m.canvas.print_figure(fname, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/React311/lib/python3.11/site-packages/matplotlib/backend_bases.py:2184\u001b[39m, in \u001b[36mFigureCanvasBase.print_figure\u001b[39m\u001b[34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[39m\n\u001b[32m   2180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2181\u001b[39m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[32m   2182\u001b[39m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[32m   2183\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m cbook._setattr_cm(\u001b[38;5;28mself\u001b[39m.figure, dpi=dpi):\n\u001b[32m-> \u001b[39m\u001b[32m2184\u001b[39m         result = print_method(\n\u001b[32m   2185\u001b[39m             filename,\n\u001b[32m   2186\u001b[39m             facecolor=facecolor,\n\u001b[32m   2187\u001b[39m             edgecolor=edgecolor,\n\u001b[32m   2188\u001b[39m             orientation=orientation,\n\u001b[32m   2189\u001b[39m             bbox_inches_restore=_bbox_inches_restore,\n\u001b[32m   2190\u001b[39m             **kwargs)\n\u001b[32m   2191\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2192\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/React311/lib/python3.11/site-packages/matplotlib/backend_bases.py:2040\u001b[39m, in \u001b[36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   2036\u001b[39m     optional_kws = {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[32m   2037\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdpi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfacecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33medgecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33morientation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2038\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbbox_inches_restore\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m   2039\u001b[39m     skip = optional_kws - {*inspect.signature(meth).parameters}\n\u001b[32m-> \u001b[39m\u001b[32m2040\u001b[39m     print_method = functools.wraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m *args, **kwargs: meth(\n\u001b[32m   2041\u001b[39m         *args, **{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m skip}))\n\u001b[32m   2042\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[32m   2043\u001b[39m     print_method = meth\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/React311/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:481\u001b[39m, in \u001b[36mFigureCanvasAgg.print_png\u001b[39m\u001b[34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[39m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, *, metadata=\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    435\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    436\u001b[39m \u001b[33;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[32m    437\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    479\u001b[39m \u001b[33;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[32m    480\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m     \u001b[38;5;28mself\u001b[39m._print_pil(filename_or_obj, \u001b[33m\"\u001b[39m\u001b[33mpng\u001b[39m\u001b[33m\"\u001b[39m, pil_kwargs, metadata)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/React311/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:430\u001b[39m, in \u001b[36mFigureCanvasAgg._print_pil\u001b[39m\u001b[34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[33;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[33;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    429\u001b[39m FigureCanvasAgg.draw(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m mpl.image.imsave(\n\u001b[32m    431\u001b[39m     filename_or_obj, \u001b[38;5;28mself\u001b[39m.buffer_rgba(), \u001b[38;5;28mformat\u001b[39m=fmt, origin=\u001b[33m\"\u001b[39m\u001b[33mupper\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    432\u001b[39m     dpi=\u001b[38;5;28mself\u001b[39m.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/React311/lib/python3.11/site-packages/matplotlib/image.py:1634\u001b[39m, in \u001b[36mimsave\u001b[39m\u001b[34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[39m\n\u001b[32m   1632\u001b[39m pil_kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[32m   1633\u001b[39m pil_kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mdpi\u001b[39m\u001b[33m\"\u001b[39m, (dpi, dpi))\n\u001b[32m-> \u001b[39m\u001b[32m1634\u001b[39m image.save(fname, **pil_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/React311/lib/python3.11/site-packages/PIL/Image.py:2591\u001b[39m, in \u001b[36mImage.save\u001b[39m\u001b[34m(self, fp, format, **params)\u001b[39m\n\u001b[32m   2589\u001b[39m         fp = builtins.open(filename, \u001b[33m\"\u001b[39m\u001b[33mr+b\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2590\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2591\u001b[39m         fp = builtins.open(filename, \u001b[33m\"\u001b[39m\u001b[33mw+b\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2592\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2593\u001b[39m     fp = cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'scratch/LLM_reaction_Robot/visualization_frames.png'"
     ]
    }
   ],
   "source": [
    "# 创建视频帧对比图\n",
    "fig, axes = plt.subplots(2, 6, figsize=(18, 6))\n",
    "fig.suptitle(f'Sample {sample_idx}: Speaker vs Listener Video Frames', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Speaker帧\n",
    "for i, (frame, idx) in enumerate(zip(speaker_frames, speaker_indices)):\n",
    "    axes[0, i].imshow(frame)\n",
    "    axes[0, i].set_title(f'Speaker\\nFrame {idx}')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# Listener帧\n",
    "for i, (frame, idx) in enumerate(zip(listener_frames, listener_indices)):\n",
    "    axes[1, i].imshow(frame)\n",
    "    axes[1, i].set_title(f'Listener\\nFrame {idx}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "output_path = '/mnt/iusers01/fatpou01/compsci01/k09562zs/scratch/LLM_reaction_Robot/visualization_frames.png'\n",
    "plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"✅ 视频帧对比图已保存: {output_path}\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd2dc0c",
   "metadata": {},
   "source": [
    "## 6. 可视化：音频波形对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b0236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建音频波形对比图\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 8))\n",
    "fig.suptitle(f'Sample {sample_idx}: Audio Waveforms', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Speaker音频\n",
    "time_speaker = np.arange(len(speaker_audio)) / sr_speaker\n",
    "axes[0].plot(time_speaker, speaker_audio, linewidth=0.5, alpha=0.8)\n",
    "axes[0].set_title('Speaker Audio', fontsize=14)\n",
    "axes[0].set_xlabel('Time (s)')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Listener音频\n",
    "time_listener = np.arange(len(listener_audio)) / sr_listener\n",
    "axes[1].plot(time_listener, listener_audio, linewidth=0.5, alpha=0.8, color='orange')\n",
    "axes[1].set_title('Listener Audio', fontsize=14)\n",
    "axes[1].set_xlabel('Time (s)')\n",
    "axes[1].set_ylabel('Amplitude')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "output_path = 'scratch/LLM_reaction_Robot/visualization_audio.png'\n",
    "plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"✅ 音频波形对比图已保存: {output_path}\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aada47",
   "metadata": {},
   "source": [
    "## 7. 可视化：Listener AU时序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a5bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取AU数据\n",
    "au_names = sample['listener_au_names']\n",
    "au_prob = sample['listener_au_prob']\n",
    "au_act = sample['listener_au_act']\n",
    "frame_idx = sample['listener_frame_idx']\n",
    "\n",
    "# 转换为时间轴（秒）\n",
    "time_axis = np.array(frame_idx) / sample['fps']\n",
    "\n",
    "# 选择几个代表性AU可视化\n",
    "representative_aus = ['AU6', 'AU12', 'AU1', 'AU4', 'AU25', 'AU26']  # 微笑、惊讶、皱眉、张嘴\n",
    "available_aus = [au for au in representative_aus if au in au_names]\n",
    "\n",
    "print(f\"可视化的AU: {available_aus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca02d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建AU概率时序图\n",
    "fig, axes = plt.subplots(len(available_aus), 1, figsize=(16, 2.5*len(available_aus)))\n",
    "if len(available_aus) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "fig.suptitle(f'Sample {sample_idx}: Listener AU Probability over Time', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, au in enumerate(available_aus):\n",
    "    prob = au_prob[au]\n",
    "    act = au_act[au]\n",
    "    \n",
    "    # 绘制概率曲线\n",
    "    axes[i].plot(time_axis, prob, linewidth=1.5, label=f'{au} Probability', color='steelblue')\n",
    "    \n",
    "    # 绘制激活区域（阴影）\n",
    "    act_array = np.array(act)\n",
    "    axes[i].fill_between(time_axis, 0, 1, where=(act_array > 0), \n",
    "                          alpha=0.2, color='red', label=f'{au} Activated')\n",
    "    \n",
    "    axes[i].set_ylabel('Probability', fontsize=11)\n",
    "    axes[i].set_ylim(-0.05, 1.05)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    axes[i].legend(loc='upper right')\n",
    "    axes[i].set_title(f'{au} - Mean prob: {np.mean(prob):.3f}, Activation rate: {np.mean(act):.1%}', \n",
    "                     fontsize=12)\n",
    "\n",
    "axes[-1].set_xlabel('Time (s)', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "output_path = 'scratch/LLM_reaction_Robot/visualization_au_timeline.png'\n",
    "plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"✅ AU时序图已保存: {output_path}\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6146cd6c",
   "metadata": {},
   "source": [
    "## 8. 统计分析：所有AU激活情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d6831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计所有AU的激活率和平均概率\n",
    "au_stats = []\n",
    "for au in au_names:\n",
    "    prob = np.array(au_prob[au])\n",
    "    act = np.array(au_act[au])\n",
    "    au_stats.append({\n",
    "        'AU': au,\n",
    "        'Mean Prob': np.mean(prob),\n",
    "        'Std Prob': np.std(prob),\n",
    "        'Activation Rate': np.mean(act),\n",
    "        'Total Activated Frames': np.sum(act)\n",
    "    })\n",
    "\n",
    "# 打印统计表\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Listener AU Statistics (Sample {sample_idx})\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'AU':<6} {'Mean Prob':<12} {'Std Prob':<12} {'Act Rate':<12} {'Act Frames':<12}\")\n",
    "print(\"-\"*80)\n",
    "for stat in au_stats:\n",
    "    print(f\"{stat['AU']:<6} {stat['Mean Prob']:<12.4f} {stat['Std Prob']:<12.4f} \"\n",
    "          f\"{stat['Activation Rate']:<12.2%} {stat['Total Activated Frames']:<12.0f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d01ecc",
   "metadata": {},
   "source": [
    "## 9. 可视化：AU激活热图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建AU激活热图（降采样以便可视化）\n",
    "downsample_factor = max(1, len(frame_idx) // 200)  # 最多显示200个时间点\n",
    "time_downsampled = time_axis[::downsample_factor]\n",
    "\n",
    "# 构建激活矩阵\n",
    "au_matrix = np.zeros((len(au_names), len(time_downsampled)))\n",
    "for i, au in enumerate(au_names):\n",
    "    au_matrix[i, :] = np.array(au_prob[au])[::downsample_factor]\n",
    "\n",
    "# 绘制热图\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "im = ax.imshow(au_matrix, aspect='auto', cmap='YlOrRd', interpolation='nearest')\n",
    "ax.set_yticks(range(len(au_names)))\n",
    "ax.set_yticklabels(au_names, fontsize=10)\n",
    "ax.set_xlabel('Time (s)', fontsize=12)\n",
    "ax.set_ylabel('Action Units', fontsize=12)\n",
    "ax.set_title(f'Sample {sample_idx}: Listener AU Probability Heatmap', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 添加时间轴刻度\n",
    "n_ticks = 10\n",
    "tick_indices = np.linspace(0, len(time_downsampled)-1, n_ticks, dtype=int)\n",
    "ax.set_xticks(tick_indices)\n",
    "ax.set_xticklabels([f'{time_downsampled[i]:.1f}' for i in tick_indices])\n",
    "\n",
    "# 添加颜色条\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('AU Probability', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "output_path = 'scratch/LLM_reaction_Robot/visualization_au_heatmap.png'\n",
    "plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"✅ AU激活热图已保存: {output_path}\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f27c566",
   "metadata": {},
   "source": [
    "## 10. 综合可视化：All-in-One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e83543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建综合可视化面板\n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "gs = fig.add_gridspec(4, 6, hspace=0.4, wspace=0.4)\n",
    "\n",
    "fig.suptitle(f'Sample {sample_idx} - Speaker→Listener AU Prediction Dataset', \n",
    "             fontsize=18, fontweight='bold', y=0.995)\n",
    "\n",
    "# Row 1: Speaker视频帧\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(gs[0, i])\n",
    "    if i < len(speaker_frames):\n",
    "        ax.imshow(speaker_frames[i])\n",
    "        ax.set_title(f'Speaker F{speaker_indices[i]}', fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Row 2: Listener视频帧\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(gs[1, i])\n",
    "    if i < len(listener_frames):\n",
    "        ax.imshow(listener_frames[i])\n",
    "        ax.set_title(f'Listener F{listener_indices[i]}', fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Row 3: 音频波形\n",
    "ax_audio = fig.add_subplot(gs[2, :])\n",
    "ax_audio.plot(time_speaker, speaker_audio, linewidth=0.5, alpha=0.7, label='Speaker')\n",
    "ax_audio.plot(time_listener, listener_audio, linewidth=0.5, alpha=0.7, label='Listener')\n",
    "ax_audio.set_xlabel('Time (s)', fontsize=10)\n",
    "ax_audio.set_ylabel('Amplitude', fontsize=10)\n",
    "ax_audio.set_title('Audio Waveforms', fontsize=11, fontweight='bold')\n",
    "ax_audio.legend()\n",
    "ax_audio.grid(True, alpha=0.3)\n",
    "\n",
    "# Row 4: AU热图\n",
    "ax_heatmap = fig.add_subplot(gs[3, :])\n",
    "im = ax_heatmap.imshow(au_matrix, aspect='auto', cmap='YlOrRd', interpolation='nearest')\n",
    "ax_heatmap.set_yticks(range(len(au_names)))\n",
    "ax_heatmap.set_yticklabels(au_names, fontsize=8)\n",
    "ax_heatmap.set_xlabel('Time (s)', fontsize=10)\n",
    "ax_heatmap.set_ylabel('AU', fontsize=10)\n",
    "ax_heatmap.set_title('Listener AU Probability Heatmap', fontsize=11, fontweight='bold')\n",
    "tick_indices = np.linspace(0, len(time_downsampled)-1, 10, dtype=int)\n",
    "ax_heatmap.set_xticks(tick_indices)\n",
    "ax_heatmap.set_xticklabels([f'{time_downsampled[i]:.1f}' for i in tick_indices], fontsize=8)\n",
    "cbar = plt.colorbar(im, ax=ax_heatmap, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Probability', fontsize=9)\n",
    "\n",
    "output_path = 'scratch/LLM_reaction_Robot/visualization_comprehensive.png'\n",
    "plt.savefig(output_path, dpi=200, bbox_inches='tight')\n",
    "print(f\"\\n✅ 综合可视化已保存: {output_path}\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ 所有可视化完成！\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd474cd8",
   "metadata": {},
   "source": [
    "## 11. 数据完整性检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n数据完整性检查:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 检查文件存在性\n",
    "checks = [\n",
    "    ('Speaker Video', Path(sample['speaker_video_path']).exists()),\n",
    "    ('Speaker Audio', Path(sample['speaker_audio_path']).exists()),\n",
    "    ('Listener Video', Path(sample['listener_video_path']).exists()),\n",
    "    ('Listener Audio', Path(sample['listener_audio_path']).exists()),\n",
    "]\n",
    "\n",
    "for name, exists in checks:\n",
    "    status = \"✅\" if exists else \"❌\"\n",
    "    print(f\"{status} {name}: {'存在' if exists else '缺失'}\")\n",
    "\n",
    "# 检查数据一致性\n",
    "print(f\"\\n数据一致性:\")\n",
    "print(f\"✅ AU数量: {len(au_names)} (预期17个)\")\n",
    "print(f\"✅ 帧索引长度: {len(frame_idx)}\")\n",
    "print(f\"✅ AU概率序列长度: {len(au_prob[au_names[0]])} (应与帧数一致)\")\n",
    "print(f\"✅ AU激活序列长度: {len(au_act[au_names[0]])} (应与帧数一致)\")\n",
    "\n",
    "all_consistent = all([\n",
    "    len(au_prob[au]) == len(frame_idx) for au in au_names\n",
    "] + [\n",
    "    len(au_act[au]) == len(frame_idx) for au in au_names\n",
    "])\n",
    "\n",
    "if all_consistent:\n",
    "    print(\"\\n✅ 所有AU序列长度一致！\")\n",
    "else:\n",
    "    print(\"\\n❌ 警告：存在长度不一致的AU序列\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f61038",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "本notebook验证了以下内容：\n",
    "\n",
    "1. ✅ 数据集成功加载（HuggingFace格式）\n",
    "2. ✅ Speaker和Listener视频帧正确配对\n",
    "3. ✅ 音频数据可正常读取\n",
    "4. ✅ Listener AU标签完整（17个AU，逐帧标注）\n",
    "5. ✅ 所有可视化图片已保存（无需GUI）\n",
    "\n",
    "**生成的可视化文件：**\n",
    "- `visualization_frames.png` - 视频帧对比\n",
    "- `visualization_audio.png` - 音频波形对比\n",
    "- `visualization_au_timeline.png` - AU时序图\n",
    "- `visualization_au_heatmap.png` - AU热图\n",
    "- `visualization_comprehensive.png` - 综合可视化\n",
    "\n",
    "数据准备完成，可以开始模型训练！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "React311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
